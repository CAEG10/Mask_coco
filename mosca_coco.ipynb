{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "mosca_coco.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPTucKIjwNypKFQ0p9WsFtM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/CAEG10/Mask_coco/blob/main/mosca_coco.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bX8XXRcY9w08"
      },
      "source": [
        "import os\n",
        "import sys\n",
        "import json\n",
        "import numpy as np\n",
        "import time\n",
        "from PIL import Image, ImageDraw\n",
        "from pathlib import Path"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-TH46UrNFYgg"
      },
      "source": [
        "!git clone https://github.com/CAEG10/Mask_coco.git"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EPzNlF1IFYTv"
      },
      "source": [
        "cd Mask_coco/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xOQE8ztlFXcF"
      },
      "source": [
        "!python setup.py install"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jBmG1sJC_bmT"
      },
      "source": [
        "ROOT_DIR = '/content/Mask_coco'\n",
        "assert os.path.exists(ROOT_DIR), 'ROOT_DIR does not exist. Did you forget to read the instructions above? ;)'\n",
        "\n",
        "# Import mrcnn libraries\n",
        "sys.path.append(ROOT_DIR) \n",
        "from mrcnn.config import Config\n",
        "import mrcnn.utils as utils\n",
        "from mrcnn import visualize\n",
        "import mrcnn.model as modellib"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_uBEHMby_fbX"
      },
      "source": [
        "# Directory to save logs and trained model\n",
        "MODEL_DIR = os.path.join(ROOT_DIR, \"logs\")\n",
        "\n",
        "# Local path to trained weights file\n",
        "COCO_MODEL_PATH = os.path.join(ROOT_DIR, \"mask_rcnn_coco.h5\")\n",
        "\n",
        "# Download COCO trained weights from Releases if needed\n",
        "if not os.path.exists(COCO_MODEL_PATH):\n",
        "    utils.download_trained_weights(COCO_MODEL_PATH)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GMWoHgal_hy7"
      },
      "source": [
        "class MoscaConfig(Config):\n",
        "    \"\"\"Configuration for training on the mosca  dataset.\n",
        "    \"\"\"\n",
        "    # Give the configuration a recognizable name\n",
        "    NAME = \"mosca\"\n",
        "\n",
        "    # Train on 1 GPU and 1 image per GPU. Batch size is 1 (GPUs * images/GPU).\n",
        "    GPU_COUNT = 1\n",
        "    IMAGES_PER_GPU = 1\n",
        "\n",
        "    # Number of classes (including background)\n",
        "    NUM_CLASSES = 1 + 1  # background + 1 (mosca)\n",
        "\n",
        "    # All of our training images are 512x512\n",
        "    IMAGE_MIN_DIM = 512\n",
        "    IMAGE_MAX_DIM = 512\n",
        "\n",
        "    # You can experiment with this number to see if it improves training\n",
        "    STEPS_PER_EPOCH = 500\n",
        "\n",
        "    # This is how often validation is run. If you are using too much hard drive space\n",
        "    # on saved models (in the MODEL_DIR), try making this value larger.\n",
        "    VALIDATION_STEPS = 5\n",
        "    \n",
        "    # Matterport originally used resnet101, but I downsized to fit it on my graphics card\n",
        "    BACKBONE = 'resnet101'\n",
        "\n",
        "    # To be honest, I haven't taken the time to figure out what these do\n",
        "    RPN_ANCHOR_SCALES = (8, 16, 32, 64, 128)\n",
        "    TRAIN_ROIS_PER_IMAGE = 32\n",
        "    MAX_GT_INSTANCES = 50 \n",
        "    POST_NMS_ROIS_INFERENCE = 500 \n",
        "    POST_NMS_ROIS_TRAINING = 1000 \n",
        "    \n",
        "config = MoscaConfig()\n",
        "config.display()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ksxJJRj9_rBi"
      },
      "source": [
        "class CocoLikeDataset(utils.Dataset):\n",
        "    \"\"\" Generates a COCO-like dataset, i.e. an image dataset annotated in the style of the COCO dataset.\n",
        "        See http://cocodataset.org/#home for more information.\n",
        "    \"\"\"\n",
        "    def load_data(self, annotation_json, images_dir):\n",
        "        \"\"\" Load the coco-like dataset from json\n",
        "        Args:\n",
        "            annotation_json: The path to the coco annotations json file\n",
        "            images_dir: The directory holding the images referred to by the json file\n",
        "        \"\"\"\n",
        "        # Load json from file\n",
        "        json_file = open(annotation_json)\n",
        "        coco_json = json.load(json_file)\n",
        "        json_file.close()\n",
        "        \n",
        "        # Add the class names using the base method from utils.Dataset\n",
        "        source_name = \"coco_like\"\n",
        "        for category in coco_json['categories']:\n",
        "            class_id = category['id']\n",
        "            class_name = category['name']\n",
        "            if class_id < 1:\n",
        "                print('Error: Class id for \"{}\" cannot be less than one. (0 is reserved for the background)'.format(class_name))\n",
        "                return\n",
        "            \n",
        "            self.add_class(source_name, class_id, class_name)\n",
        "        \n",
        "        # Get all annotations\n",
        "        annotations = {}\n",
        "        for annotation in coco_json['annotations']:\n",
        "            image_id = annotation['image_id']\n",
        "            if image_id not in annotations:\n",
        "                annotations[image_id] = []\n",
        "            annotations[image_id].append(annotation)\n",
        "        \n",
        "        # Get all images and add them to the dataset\n",
        "        seen_images = {}\n",
        "        for image in coco_json['images']:\n",
        "            image_id = image['id']\n",
        "            if image_id in seen_images:\n",
        "                print(\"Warning: Skipping duplicate image id: {}\".format(image))\n",
        "            else:\n",
        "                seen_images[image_id] = image\n",
        "                try:\n",
        "                    image_file_name = image['file_name']\n",
        "                    image_width = image['width']\n",
        "                    image_height = image['height']\n",
        "                except KeyError as key:\n",
        "                    print(\"Warning: Skipping image (id: {}) with missing key: {}\".format(image_id, key))\n",
        "                \n",
        "                image_path = os.path.abspath(os.path.join(images_dir, image_file_name))\n",
        "                image_annotations = annotations[image_id]\n",
        "                \n",
        "                # Add the image using the base method from utils.Dataset\n",
        "                self.add_image(\n",
        "                    source=source_name,\n",
        "                    image_id=image_id,\n",
        "                    path=image_path,\n",
        "                    width=image_width,\n",
        "                    height=image_height,\n",
        "                    annotations=image_annotations\n",
        "                )\n",
        "                \n",
        "    def load_mask(self, image_id):\n",
        "        \"\"\" Load instance masks for the given image.\n",
        "        MaskRCNN expects masks in the form of a bitmap [height, width, instances].\n",
        "        Args:\n",
        "            image_id: The id of the image to load masks for\n",
        "        Returns:\n",
        "            masks: A bool array of shape [height, width, instance count] with\n",
        "                one mask per instance.\n",
        "            class_ids: a 1D array of class IDs of the instance masks.\n",
        "        \"\"\"\n",
        "        image_info = self.image_info[image_id]\n",
        "        annotations = image_info['annotations']\n",
        "        instance_masks = []\n",
        "        class_ids = []\n",
        "        \n",
        "        for annotation in annotations:\n",
        "            class_id = annotation['category_id']\n",
        "            mask = Image.new('1', (image_info['width'], image_info['height']))\n",
        "            mask_draw = ImageDraw.ImageDraw(mask, '1')\n",
        "            for segmentation in annotation['segmentation']:\n",
        "                mask_draw.polygon(segmentation, fill=1)\n",
        "                bool_array = np.array(mask) > 0\n",
        "                instance_masks.append(bool_array)\n",
        "                class_ids.append(class_id)\n",
        "\n",
        "        mask = np.dstack(instance_masks)\n",
        "        class_ids = np.array(class_ids, dtype=np.int32)\n",
        "        \n",
        "        return mask, class_ids"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lHA1a00j_wGn"
      },
      "source": [
        "dataset_train = MoscaDataset()\n",
        "dataset_train.load_moscas(\"/content/Mask_coco/dataset/mosca\", \"train\")\n",
        "dataset_train.prepare()\n",
        "\n",
        "# Validation dataset\n",
        "dataset_val = MoscaDataset()\n",
        "dataset_val.load_moscas(\"/content/Mask_coco/dataset/mosca\", \"val\")\n",
        "dataset_val.prepare()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IuOT25d9_6Vx"
      },
      "source": [
        "for name, dataset in [('training', dataset_train), ('validation', dataset_val)]:\n",
        "    print(f'Displaying examples from {name} dataset:')\n",
        "    \n",
        "    image_ids = np.random.choice(dataset.image_ids, 3)\n",
        "    for image_id in image_ids:\n",
        "        image = dataset.load_image(image_id)\n",
        "        mask, class_ids = dataset.load_mask(image_id)\n",
        "        visualize.display_top_masks(image, mask, class_ids, dataset.class_names)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wWN1YLyBAJDs"
      },
      "source": [
        "# Create model in training mode\n",
        "model = modellib.MaskRCNN(mode=\"training\", config=config,\n",
        "                          model_dir=MODEL_DIR)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IhE_uvHcALWg"
      },
      "source": [
        "# Which weights to start with?\n",
        "init_with = \"coco\"  # imagenet, coco, or last\n",
        "\n",
        "if init_with == \"imagenet\":\n",
        "    model.load_weights(model.get_imagenet_weights(), by_name=True)\n",
        "elif init_with == \"coco\":\n",
        "    # Load weights trained on MS COCO, but skip layers that\n",
        "    # are different due to the different number of classes\n",
        "    # See README for instructions to download the COCO weights\n",
        "    model.load_weights(COCO_MODEL_PATH, by_name=True,\n",
        "                       exclude=[\"mrcnn_class_logits\", \"mrcnn_bbox_fc\", \n",
        "                                \"mrcnn_bbox\", \"mrcnn_mask\"])\n",
        "elif init_with == \"last\":\n",
        "    # Load the last model you trained and continue training\n",
        "    model.load_weights(model.find_last(), by_name=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Y2CyllGAVel"
      },
      "source": [
        "# Train the head branches\n",
        "# Passing layers=\"heads\" freezes all layers except the head\n",
        "# layers. You can also pass a regular expression to select\n",
        "# which layers to train by name pattern.\n",
        "start_train = time.time()\n",
        "model.train(dataset_train, dataset_val, \n",
        "            learning_rate=config.LEARNING_RATE, \n",
        "            epochs=4, \n",
        "            layers='heads')\n",
        "end_train = time.time()\n",
        "minutes = round((end_train - start_train) / 60, 2)\n",
        "print(f'Training took {minutes} minutes')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7w2pCNdoA9uX"
      },
      "source": [
        "# Fine tune all layers\n",
        "# Passing layers=\"all\" trains all layers. You can also \n",
        "# pass a regular expression to select which layers to\n",
        "# train by name pattern.\n",
        "start_train = time.time()\n",
        "model.train(dataset_train, dataset_val, \n",
        "            learning_rate=config.LEARNING_RATE / 10,\n",
        "            epochs=8, \n",
        "            layers=\"all\")\n",
        "end_train = time.time()\n",
        "minutes = round((end_train - start_train) / 60, 2)\n",
        "print(f'Training took {minutes} minutes')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FNZgBPXaBEx4"
      },
      "source": [
        "class InferenceConfig(CocoSynthConfig):\n",
        "    GPU_COUNT = 1\n",
        "    IMAGES_PER_GPU = 1\n",
        "    IMAGE_MIN_DIM = 512\n",
        "    IMAGE_MAX_DIM = 512\n",
        "    DETECTION_MIN_CONFIDENCE = 0.85\n",
        "    \n",
        "\n",
        "inference_config = InferenceConfig()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "631ZIuBgBSDE"
      },
      "source": [
        "# Recreate the model in inference mode\n",
        "model = modellib.MaskRCNN(mode=\"inference\", \n",
        "                          config=inference_config,\n",
        "                          model_dir=MODEL_DIR)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pmQayuTlBSqI"
      },
      "source": [
        "# Get path to saved weights\n",
        "# Either set a specific path or find last trained weights\n",
        "# model_path = str(Path(ROOT_DIR) / \"logs\" / \"box_synthetic20190328T2255/mask_rcnn_box_synthetic_0016.h5\" )\n",
        "model_path = model.find_last()\n",
        "\n",
        "# Load trained weights (fill in path to trained weights here)\n",
        "assert model_path != \"\", \"Provide path to trained weights\"\n",
        "print(\"Loading weights from \", model_path)\n",
        "model.load_weights(model_path, by_name=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tHzrO2D3BVgn"
      },
      "source": [
        "import skimage\n",
        "\n",
        "real_test_dir = '/content/Mask_coco/dataset/mosca/test/'\n",
        "image_paths = []\n",
        "for filename in os.listdir(real_test_dir):\n",
        "    if os.path.splitext(filename)[1].lower() in ['.png', '.jpg', '.jpeg']:\n",
        "        image_paths.append(os.path.join(real_test_dir, filename))\n",
        "\n",
        "for image_path in image_paths:\n",
        "    img = skimage.io.imread(image_path)\n",
        "    img_arr = np.array(img)\n",
        "    results = model.detect([img_arr], verbose=1)\n",
        "    r = results[0]\n",
        "    visualize.display_instances(img, r['rois'], r['masks'], r['class_ids'], \n",
        "                                dataset_train.class_names, r['scores'], figsize=(8,8))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AhVfWHhFBlq6"
      },
      "source": [
        "Video Inference"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l_VD91EHBqLI"
      },
      "source": [
        "video_file = Path(\"../datasets/box_dataset_synthetic/videotest/boxvideo_24fps.mp4\")\n",
        "video_save_dir = Path(\"../datasets/box_dataset_synthetic/videotest/save\")\n",
        "video_save_dir.mkdir(exist_ok=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_qs7WlnQBt16"
      },
      "source": [
        "\n",
        "class VideoInferenceConfig(CocoSynthConfig):\n",
        "    GPU_COUNT = 1\n",
        "    IMAGES_PER_GPU = 1\n",
        "    IMAGE_MIN_DIM = 1088\n",
        "    IMAGE_MAX_DIM = 1920\n",
        "    IMAGE_SHAPE = [1920, 1080, 3]\n",
        "    DETECTION_MIN_CONFIDENCE = 0.80\n",
        "    \n",
        "\n",
        "inference_config = VideoInferenceConfig()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "95VgL2N-Dd0f"
      },
      "source": [
        "# Recreate the model in inference mode\n",
        "model = modellib.MaskRCNN(mode=\"inference\", \n",
        "                          config=inference_config,\n",
        "                          model_dir=MODEL_DIR)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U9qYOwkVDhH5"
      },
      "source": [
        "# Get path to saved weights\n",
        "# Either set a specific path or find last trained weights\n",
        "# model_path = str(Path(ROOT_DIR) / \"logs\" / \"box_synthetic20190328T2255/mask_rcnn_box_synthetic_0016.h5\" )\n",
        "model_path = model.find_last()\n",
        "\n",
        "# Load trained weights (fill in path to trained weights here)\n",
        "assert model_path != \"\", \"Provide path to trained weights\"\n",
        "print(\"Loading weights from \", model_path)\n",
        "model.load_weights(model_path, by_name=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s-fiGpe1Djiw"
      },
      "source": [
        "import cv2\n",
        "import skimage\n",
        "import random\n",
        "import colorsys\n",
        "from tqdm import tqdm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v9tFLA2yDl7I"
      },
      "source": [
        "def random_colors(N, bright=True):\n",
        "    \"\"\" Generate random colors. \n",
        "        To get visually distinct colors, generate them in HSV space then\n",
        "        convert to RGB.\n",
        "    Args:\n",
        "        N: the number of colors to generate\n",
        "        bright: whether or not to use bright colors\n",
        "    Returns:\n",
        "        a list of RGB colors, e.g [(0.0, 1.0, 0.0), (1.0, 0.0, 0.5), ...]\n",
        "    \"\"\"\n",
        "    brightness = 1.0 if bright else 0.7\n",
        "    hsv = [(i / N, 1, brightness) for i in range(N)]\n",
        "    colors = list(map(lambda c: colorsys.hsv_to_rgb(*c), hsv))\n",
        "    random.shuffle(colors)\n",
        "    return colors\n",
        "\n",
        "def apply_mask(image, mask, color, alpha=0.5):\n",
        "    \"\"\" Apply the given mask to the image.\n",
        "    Args:\n",
        "        image: a cv2 image\n",
        "        mask: a mask of which pixels to color\n",
        "        color: the color to use\n",
        "        alpha: how visible the mask should be (0 to 1)\n",
        "    Returns:\n",
        "        a cv2 image with mask applied\n",
        "    \"\"\"\n",
        "    for c in range(3):\n",
        "        image[:, :, c] = np.where(mask == 1,\n",
        "                                  image[:, :, c] *\n",
        "                                  (1 - alpha) + alpha * color[c] * 255,\n",
        "                                  image[:, :, c])\n",
        "    return image\n",
        "\n",
        "def display_instances(image, boxes, masks, ids, names, scores, colors):\n",
        "    \"\"\" Take the image and results and apply the mask, box, and label\n",
        "    Args:\n",
        "        image: a cv2 image\n",
        "        boxes: a list of bounding boxes to display\n",
        "        masks: a list of masks to display\n",
        "        ids: a list of class ids\n",
        "        names: a list of class names corresponding to the ids\n",
        "        scores: a list of scores of each instance detected\n",
        "        colors: a list of colors to use\n",
        "    Returns:\n",
        "        a cv2 image with instances displayed   \n",
        "    \"\"\"\n",
        "    n_instances = boxes.shape[0]\n",
        "\n",
        "    if not n_instances:\n",
        "        return image # no instances\n",
        "    else:\n",
        "        assert boxes.shape[0] == masks.shape[-1] == ids.shape[0]\n",
        "\n",
        "    for i, color in enumerate(colors):\n",
        "        # Check if any boxes to show\n",
        "        if not np.any(boxes[i]):\n",
        "            continue\n",
        "        \n",
        "        # Check if any scores to show\n",
        "        if scores is not None:\n",
        "            score = scores[i] \n",
        "        else:\n",
        "            score = None\n",
        "\n",
        "        # Add the mask\n",
        "        image = apply_mask(image, masks[:, :, i], color)\n",
        "        \n",
        "        # Add the bounding box\n",
        "        y1, x1, y2, x2 = boxes[i]\n",
        "        image = cv2.rectangle(image, (x1, y1), (x2, y2), color, 2)\n",
        "        \n",
        "        # Add the label\n",
        "        label = names[ids[i]]\n",
        "        if score:\n",
        "            label = f'{label} {score:.2f}'\n",
        "            \n",
        "        label_pos = (x1 + (x2 - x1) // 2, y1 + (y2 - y1) // 2) # center of bounding box\n",
        "        image = cv2.putText(image, label, label_pos, cv2.FONT_HERSHEY_DUPLEX, 0.7, color, 2)\n",
        "\n",
        "    return image"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NSeegGgxDp6I"
      },
      "source": [
        "video_file = Path(\"../datasets/box_dataset_synthetic/videotest/boxvideo_24fps.mp4\")\n",
        "video_save_dir = Path(\"../datasets/box_dataset_synthetic/videotest/save\")\n",
        "video_save_dir.mkdir(exist_ok=True)\n",
        "vid_name = video_save_dir / \"output.mp4\"\n",
        "v_format=\"FMP4\"\n",
        "fourcc = cv2.VideoWriter_fourcc(*v_format)\n",
        "\n",
        "print('Writing output video to: ' + str(vid_name))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "us4oMguKDqdz"
      },
      "source": [
        "#colors = random_colors(30)\n",
        "colors = [(1.0, 1.0, 0.0)] * 30\n",
        "\n",
        "# Change color representation from RGB to BGR before displaying instances\n",
        "colors = [(color[2], color[1], color[0]) for color in colors]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9KAvLfieDsSn"
      },
      "source": [
        "input_video = cv2.VideoCapture(str(video_file))\n",
        "frame_count = int(input_video.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "fps = int(input_video.get(cv2.CAP_PROP_FPS))\n",
        "output_video = None\n",
        "vid_size = None\n",
        "current_frame = 0\n",
        "\n",
        "for i in tqdm(range(frame_count)):\n",
        "    # Read the current frame\n",
        "    ret, frame = input_video.read()\n",
        "    if not ret:\n",
        "        break\n",
        "        \n",
        "    current_frame += 1\n",
        "    \n",
        "    # Change color representation from BGR to RGB before running model.detect()\n",
        "    detect_frame = frame[:, :, ::-1]        \n",
        "    \n",
        "    # Run inference on the color-adjusted frame\n",
        "    results = model.detect([detect_frame], verbose=0)\n",
        "    r = results[0]\n",
        "    n_instances = r['rois'].shape[0]\n",
        "    \n",
        "    # Make sure we have enough colors\n",
        "    if len(colors) < n_instances:\n",
        "        # not enough colors, generate more\n",
        "        more_colors = random_colors(n_instances - len(colors))\n",
        "        \n",
        "        # Change color representation from RGB to BGR before displaying instances\n",
        "        more_colors = [(color[2], color[1], color[0]) for color in more_colors]\n",
        "        colors += more_colors\n",
        "        \n",
        "    \n",
        "    \n",
        "    # Display instances on the original frame\n",
        "    display_frame = display_instances(frame, r['rois'], r['masks'], r['class_ids'], \n",
        "                                dataset_train.class_names, r['scores'], colors[0:n_instances])\n",
        "\n",
        "    # Make sure we got displayed instances\n",
        "    if display_frame is not None:\n",
        "        frame = display_frame\n",
        "\n",
        "    # Create the output_video if it doesn't yet exist\n",
        "    if output_video is None:\n",
        "        if vid_size is None:\n",
        "            vid_size = frame.shape[1], frame.shape[0]\n",
        "        output_video = cv2.VideoWriter(str(vid_name), fourcc, float(fps), vid_size, True)\n",
        "        \n",
        "    # Resize frame if necessary\n",
        "    if vid_size[0] != frame.shape[1] and vid_size[1] != frame.shape[0]:\n",
        "        frame = cv2.resize(frame, vid_size)\n",
        "    \n",
        "    # Write the frame to the output_video\n",
        "    output_video.write(frame)\n",
        "    \n",
        "input_video.release()\n",
        "output_video.release()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}